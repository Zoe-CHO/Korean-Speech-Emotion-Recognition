{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zoe-CHO/Korean-Speech-Emotion-Recognition/blob/main/week4_%EC%A1%B0%EC%B0%AC%EC%96%91.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq2bSCvDX9ZQ"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_fmnist=keras.datasets.fashion_mnist\n",
        "data_mnist=keras.datasets.mnist\n",
        "\n",
        "# Getting the In-distribution Data (MNIST)\n",
        "(X_train, y_train), (X_test, y_test)=data_mnist.load_data()\n",
        "\n",
        "# Creating Validation and Test set\n",
        "X_val=X_train[:5000]\n",
        "y_val=y_train[:5000]\n",
        "\n",
        "X_train=X_train[5000:]\n",
        "y_train=y_train[5000:]\n",
        "\n",
        "# Normalizing the In-distribution Data\n",
        "X_train=X_train/255\n",
        "X_test=X_test/255\n",
        "\n",
        "\n",
        "# Getting the Out-of-distribution Data (Fashion MNIST)\n",
        "_, (X_ood, y_ood)=data_fmnist.load_data()\n",
        "\n",
        "# Normalizing the Out-of-distribution Data\n",
        "X_ood=X_ood/255\n",
        "\n",
        "# Reshaping the Data\n",
        "X_train=X_train.reshape(-1, 28, 28, 1)\n",
        "X_val=X_val.reshape(-1, 28, 28, 1)\n",
        "X_test=X_test.reshape(-1, 28, 28, 1)\n",
        "X_ood=X_ood.reshape(-1, 28, 28, 1)"
      ],
      "metadata": {
        "id": "-x2bNZCAYExi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Convolutional Neural Network\n",
        "model = keras.models.Sequential([\n",
        "        keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
        "                            input_shape=[28, 28, 1]),\n",
        "        keras.layers.MaxPooling2D(2),\n",
        "        keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "        keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "        keras.layers.MaxPooling2D(2),\n",
        "        keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "        keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "        keras.layers.MaxPooling2D(2),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(128, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(64, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "K1E9qiNsYWwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Training the model on Downstream Task\n",
        "history=model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRTZz_VSYxiw",
        "outputId": "1f934220-719f-442f-f58e-68714769c90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 19s 8ms/step - loss: 1.2580 - accuracy: 0.5722 - val_loss: 20.2550 - val_accuracy: 0.9510\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3071 - accuracy: 0.9150 - val_loss: 17.0150 - val_accuracy: 0.9704\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.1951 - accuracy: 0.9488 - val_loss: 11.4919 - val_accuracy: 0.9802\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.1490 - accuracy: 0.9621 - val_loss: 11.9799 - val_accuracy: 0.9834\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.1208 - accuracy: 0.9689 - val_loss: 9.3657 - val_accuracy: 0.9862\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.1019 - accuracy: 0.9736 - val_loss: 12.2360 - val_accuracy: 0.9816\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0918 - accuracy: 0.9775 - val_loss: 8.7173 - val_accuracy: 0.9872\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0807 - accuracy: 0.9796 - val_loss: 10.0464 - val_accuracy: 0.9866\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0710 - accuracy: 0.9824 - val_loss: 9.5147 - val_accuracy: 0.9904\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.0651 - accuracy: 0.9838 - val_loss: 12.1723 - val_accuracy: 0.9864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing Predictions and Maximum Softmax Values of Models\n",
        "pred_ood = model.predict(X_ood)\n",
        "pred_test = model.predict(X_test)\n",
        "\n",
        "maxpred_ood = tf.reduce_max(pred_ood, axis=1)\n",
        "maxpred_test = tf.reduce_max(pred_test, axis=1)"
      ],
      "metadata": {
        "id": "x_kLzaRQhSDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the Threshold for Distinguishing In-distribution/Out-of-distribution Data\n",
        "threshold = 0.99\n",
        "\n",
        "# Counting the Number of Data Counted as In-distribution\n",
        "numid_ood = tf.math.greater(maxpred_ood, threshold)\n",
        "numid_ood = tf.math.reduce_sum(tf.cast(numid_ood, tf.int32))\n",
        "\n",
        "numid_test = tf.math.greater(maxpred_test, threshold)\n",
        "numid_test = tf.math.reduce_sum(tf.cast(numid_test, tf.int32))\n",
        "\n",
        "# Computing the True Positive Rate and False Positive Rate\n",
        "num_ood = 10000\n",
        "num_test = 10000\n",
        "\n",
        "TPR = numid_test / num_test\n",
        "FPR = numid_ood / num_ood\n",
        "\n",
        "print(TPR, FPR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLDkmUbvjt_o",
        "outputId": "0930ea5b-a0f9-4f36-9f64-5dc3bf7147d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.9649, shape=(), dtype=float64) tf.Tensor(0.1534, shape=(), dtype=float64)\n"
          ]
        }
      ]
    }
  ]
}